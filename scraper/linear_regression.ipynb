{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from urllib.request import urlopen\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import pdb\n",
    "import requests\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBA_URL = 'https://www.basketball-reference.com'\n",
    "TEAMS = [\n",
    "    #Initials, Name\n",
    "    ('ATL', 'Hawks'),\n",
    "    ('BOS', 'Celtics'),\n",
    "    ('BRK', 'Nets'),\n",
    "    ('CHI', 'Bulls'),\n",
    "    ('CHO', 'Hornets'),\n",
    "    ('CLE', 'Cavaliers'),\n",
    "    ('DAL', 'Mavericks'),\n",
    "    ('DEN', 'Nuggets'),\n",
    "    ('DET', 'Pistons'),\n",
    "    ('GSW', 'Warriors'),\n",
    "    ('HOU', 'Rockets'),\n",
    "    ('IND', 'Pacers'),\n",
    "    ('LAC', 'Clippers'),\n",
    "    ('LAL', 'Lakers'),\n",
    "    ('MEM', 'Grizzlies'),\n",
    "    ('MIA', 'Heat'),\n",
    "    ('MIL', 'Bucks'),\n",
    "    ('MIN', 'Timberwolves'),\n",
    "    ('NOP', 'Pelicans'),\n",
    "    ('NYK', 'Knicks'),\n",
    "    ('OKC', 'Thunder'),\n",
    "    ('ORL', 'Magic'),\n",
    "    ('PHI', '76ers'),\n",
    "    ('PHO', 'Suns'),\n",
    "    ('POR', 'Trailblazers'),\n",
    "    ('SAC', 'Kings'),\n",
    "    ('SAS', 'Spurs'),\n",
    "    ('TOR', 'Raptors'),\n",
    "    ('UTA', 'Jazz'),\n",
    "    ('WAS', 'Wizards')\n",
    "]\n",
    "TEAM_NAMES = dict()\n",
    "\n",
    "def get_season_data_per_poss(year):\n",
    "    with (open(\"Data/\" + str(year) + \"/all_team-stats-per_poss.pkl\", \"rb\")) as openfile:\n",
    "        data = pickle.load(openfile)\n",
    "    with (open(\"Data/\" + str(year) + \"/all_opponent-stats-per_poss.pkl\", \"rb\")) as openfile:\n",
    "        opp_data = pickle.load(openfile)\n",
    "    return data, opp_data\n",
    "\n",
    "def get_season_data(year):\n",
    "    with (open(\"Data/\" + str(year) + \"/all_team-stats-base.pkl\", \"rb\")) as openfile:\n",
    "        data = pickle.load(openfile)\n",
    "    with (open(\"Data/\" + str(year) + \"/all_opponent-stats-base.pkl\", \"rb\")) as openfile:\n",
    "        opp_data = pickle.load(openfile)\n",
    "    return data, opp_data\n",
    "\n",
    "    #ratio, wins = convert_data_to_ratio(data)\n",
    "def convert_data_to_ratio(data):\n",
    "    wins = data[data.columns[-1]]\n",
    "    data = data.drop(labels='Win', axis=1)\n",
    "    columns = data.columns\n",
    "    for column in columns:\n",
    "        if '%' in column:\n",
    "            data = data.drop(column, axis=1)\n",
    "    away = data[data.columns[:len(data.columns)//2]]\n",
    "    home = data[data.columns[len(data.columns)//2:]]\n",
    "    ratio = []\n",
    "    for index, row in away.iterrows():\n",
    "        away_row = np.array(away.iloc[index], dtype=np.float)\n",
    "        home_row = np.array(home.iloc[index], dtype=np.float)\n",
    "        home_row[home_row == 0] = 1\n",
    "        ratio.append(away_row / home_row)\n",
    "    assert(len(ratio) == len(wins))\n",
    "    return ratio, wins\n",
    "def get_team_names(year):\n",
    "    rtn = []\n",
    "    standings_soup = \"https://www.basketball-reference.com/leagues/NBA_\" + str(year) + \"_standings.html\"\n",
    "    standings_soup = BeautifulSoup(urlopen(standings_soup), 'html.parser')\n",
    "    comment = standings_soup.find(\"div\",  id='all_expanded_standings')\\\n",
    "            .findAll(text=lambda text:isinstance(text, Comment))\n",
    "    extracted_comment = comment[0].extract()\n",
    "    standings_soup = BeautifulSoup(extracted_comment)\n",
    "    rows = standings_soup.find('tbody').findAll(\"tr\")\n",
    "    for row in rows:\n",
    "        rtn.append(row.find(\"td\", attrs={'data-stat': \"team_name\"}).getText())\n",
    "    return sorted(rtn)\n",
    "    \n",
    "    \n",
    "# training data: previous year's stats + current season stats\n",
    "def get_team_cumulative_stats(year):\n",
    "    team_stats = dict()\n",
    "    for initials, name in TEAMS:\n",
    "        with (open(\"Data/\" + str(year-1) + \"/\" + str(initials) + \\\n",
    "                   \"_season_game_basic_cumulative_stats.pkl\", \"rb\")) as openfile:    \n",
    "            team_stats[initials] = pickle.load(openfile)\n",
    "    return team_stats\n",
    "def get_total_games(team_stats):\n",
    "    num_games = 0\n",
    "    for key in team_stats:\n",
    "        num_games +=  team_stats[key].shape[0]\n",
    "    return num_games\n",
    "    \n",
    "#create training data\n",
    "def get_training_data(year):\n",
    "    training_data = []\n",
    "    results = []\n",
    "    team_names = get_team_names(year)\n",
    "    assert(team_names == get_team_names(year-1))\n",
    "    \n",
    "    team_cumulative_stats = get_team_cumulative_stats(year)\n",
    "    season_data, season_opp_data = get_season_data_per_poss(year-1)\n",
    "    season_data_dict = convert_season_data_to_dict(season_data, team_names)\n",
    "    season_opp_data_dict = convert_season_data_to_dict(season_opp_data, team_names)\n",
    "    for key in season_data_dict.keys():\n",
    "        assert(key in season_opp_data_dict)\n",
    "        season_data_dict[key] = np.concatenate((season_data_dict[key], season_opp_data_dict[key]), axis=None)\n",
    "    sample = \"https://www.basketball-reference.com/leagues/NBA_2019_games.html\"\n",
    "    year_soup = BeautifulSoup(urlopen(sample), 'html.parser')\n",
    "    months = year_soup.find(\"div\", attrs={'class': 'filter'})\n",
    "    months = months.findAll(\"a\")\n",
    "    months = [NBA_URL + month['href'] for month in months]\n",
    "    \n",
    "    for month in months:\n",
    "        month_soup = BeautifulSoup(urlopen(month), 'html.parser')\n",
    "        games = month_soup.find(\"table\", attrs={'id': 'schedule'}).find('tbody').findAll(\"tr\")\n",
    "        for game in games:\n",
    "            game_data = []\n",
    "            win = 0\n",
    "            if game.find('td') and game.find('td', attrs={'data-stat':'visitor_pts'}) \\\n",
    "                and game.find('td', attrs={'data-stat':'visitor_pts'}).getText():\n",
    "                away = game.find('td', attrs={'data-stat':'visitor_team_name'}).getText()\n",
    "                home = game.find('td', attrs={'data-stat':'home_team_name'}).getText()\n",
    "                away_pts = game.find('td', attrs={'data-stat':'visitor_pts'}).getText()\n",
    "                away_pts = int(away_pts)\n",
    "                home_pts = game.find('td', attrs={'data-stat':'home_pts'}).getText()\n",
    "                home_pts = int(home_pts)\n",
    "                game_data.extend(season_data_dict[away])\n",
    "                game_data.extend(season_data_dict[home])\n",
    "                assert(home_pts != away_pts)\n",
    "                if home_pts > away_pts:\n",
    "                    win = 1\n",
    "                results.append(win)\n",
    "                training_data.append(game_data)\n",
    "    assert(len(training_data) == len(results))\n",
    "    return training_data, results\n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "def convert_season_data_to_dict(pandas_frame, team_names):\n",
    "    pandas_frame.drop([column for column in list(pandas_frame) if '%' in column], inplace=True, axis=1)\n",
    "    pandas_frame.drop([column for column in list(pandas_frame) if 'FG' in column], inplace=True, axis=1)\n",
    "    pandas_frame.drop([column for column in list(pandas_frame) if 'PTS' in column], inplace=True, axis=1)\n",
    "    output = dict()\n",
    "    count = 0\n",
    "    for team in pandas_frame['Team']:\n",
    "        for team_name in team_names:\n",
    "            if team_name in team:\n",
    "                row = pandas_frame.iloc[count, 3:]\n",
    "                output[team_name] = row.values\n",
    "        count += 1\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_training_data()\n",
    "data, results = get_training_data(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data).astype(float)\n",
    "results = np.array(results).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6395348837209303\n",
      "0.5736434108527132\n",
      "0.6472868217054264\n",
      "Root mean squared error:  0.36046511627906974\n",
      "R2 score:  -0.47383292383292375\n",
      "Polynomial Root mean squared error:  0.4263565891472868\n",
      "Polynomial R2 score:  -0.7614200595829197\n",
      "Logistic Root mean squared error:  0.35271317829457366\n",
      "Logistic R2 score:  -0.4421375921375921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "regression_model = LinearRegression()\n",
    "for train_index, test_index in kFold.split(data):\n",
    "    \n",
    "    train_data, train_result = data[train_index], results[train_index]\n",
    "    test_data, test_result = data[test_index], results[test_index]\n",
    "    regression_model.fit(train_data, train_result)\n",
    "    test_prediction = regression_model.predict(test_data)\n",
    "\n",
    "    total = len(test_prediction)\n",
    "    correct = 0\n",
    "    for i in range(len(test_prediction)):\n",
    "        if test_prediction[i] > 0.5:\n",
    "            test_prediction[i] = 1\n",
    "        else:\n",
    "            test_prediction[i] = 0\n",
    "        if test_prediction[i] == test_result[i]:\n",
    "            correct += 1\n",
    "    print(float(correct)/ total)\n",
    "    rmse = mean_squared_error(test_result, test_prediction)\n",
    "    r2 = r2_score(test_result, test_prediction)\n",
    "    \n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree=2)\n",
    "    train_data_poly = polynomial_features.fit_transform(train_data)\n",
    "    test_data_poly = polynomial_features.fit_transform(test_data)\n",
    "    polynomial_model = LinearRegression()\n",
    "    polynomial_model.fit(train_data_poly,train_result)\n",
    "    polynomial_test_prediction = polynomial_model.predict(test_data_poly)\n",
    "    total = len(polynomial_test_prediction)\n",
    "    correct = 0\n",
    "    for i in range(len(polynomial_test_prediction)):\n",
    "        if polynomial_test_prediction[i] > 0.5:\n",
    "            polynomial_test_prediction[i] = 1\n",
    "        else:\n",
    "            polynomial_test_prediction[i] = 0\n",
    "        if polynomial_test_prediction[i] == test_result[i]:\n",
    "            correct += 1\n",
    "    print(float(correct)/ total)\n",
    "    \n",
    "    rsme_polynomial = mean_squared_error(test_result, polynomial_test_prediction)\n",
    "    r2_polynomial = r2_score(polynomial_test_prediction, test_result)\n",
    "    \n",
    "# model evaluation\n",
    "    logistic_model = LogisticRegression()\n",
    "    logistic_model.fit(train_data, train_result)\n",
    "    logistic_test_prediction = logistic_model.predict(test_data)\n",
    "    test_prediction = logistic_test_prediction\n",
    "    \n",
    "    total = len(test_prediction)\n",
    "    correct = 0\n",
    "    for i in range(len(test_prediction)):\n",
    "        if test_prediction[i] > 0.5:\n",
    "            test_prediction[i] = 1\n",
    "        else:\n",
    "            test_prediction[i] = 0\n",
    "        if test_prediction[i] == test_result[i]:\n",
    "            correct += 1\n",
    "    print(float(correct)/ total)\n",
    "    rmse_logistic = mean_squared_error(test_result, test_prediction)\n",
    "    r2_logistic = r2_score(test_result, test_prediction)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# printing values\n",
    "    #print('Slope:' ,regression_model.coef_)\n",
    "    #print('Intercept:', regression_model.intercept_)\n",
    "    print('Root mean squared error: ', rmse)\n",
    "    print('R2 score: ', r2)\n",
    "    \n",
    "    print('Polynomial Root mean squared error: ', rsme_polynomial)\n",
    "    print('Polynomial R2 score: ', r2_polynomial)\n",
    "        \n",
    "    print('Logistic Root mean squared error: ', rmse_logistic)\n",
    "    print('Logistic R2 score: ', r2_logistic)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
