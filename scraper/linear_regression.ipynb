{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from urllib.request import urlopen\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import pdb\n",
    "import requests\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBA_URL = 'https://www.basketball-reference.com'\n",
    "TEAMS = [\n",
    "    #Initials, Name\n",
    "    ('ATL', 'Hawks'),\n",
    "    ('BOS', 'Celtics'),\n",
    "    ('BRK', 'Nets'),\n",
    "    ('CHI', 'Bulls'),\n",
    "    ('CHO', 'Hornets'),\n",
    "    ('CLE', 'Cavaliers'),\n",
    "    ('DAL', 'Mavericks'),\n",
    "    ('DEN', 'Nuggets'),\n",
    "    ('DET', 'Pistons'),\n",
    "    ('GSW', 'Warriors'),\n",
    "    ('HOU', 'Rockets'),\n",
    "    ('IND', 'Pacers'),\n",
    "    ('LAC', 'Clippers'),\n",
    "    ('LAL', 'Lakers'),\n",
    "    ('MEM', 'Grizzlies'),\n",
    "    ('MIA', 'Heat'),\n",
    "    ('MIL', 'Bucks'),\n",
    "    ('MIN', 'Timberwolves'),\n",
    "    ('NOP', 'Pelicans'),\n",
    "    ('NYK', 'Knicks'),\n",
    "    ('OKC', 'Thunder'),\n",
    "    ('ORL', 'Magic'),\n",
    "    ('PHI', '76ers'),\n",
    "    ('PHO', 'Suns'),\n",
    "    ('POR', 'Trailblazers'),\n",
    "    ('SAC', 'Kings'),\n",
    "    ('SAS', 'Spurs'),\n",
    "    ('TOR', 'Raptors'),\n",
    "    ('UTA', 'Jazz'),\n",
    "    ('WAS', 'Wizards')\n",
    "]\n",
    "TEAM_NAMES = dict()\n",
    "\n",
    "def get_season_data_per_poss(year):\n",
    "    with (open(\"Data/\" + str(year) + \"/all_team-stats-per_poss.pkl\", \"rb\")) as openfile:\n",
    "        data = pickle.load(openfile)\n",
    "    with (open(\"Data/\" + str(year) + \"/all_opponent-stats-per_poss.pkl\", \"rb\")) as openfile:\n",
    "        opp_data = pickle.load(openfile)\n",
    "    return data, opp_data\n",
    "\n",
    "def get_season_data(year):\n",
    "    with (open(\"Data/\" + str(year) + \"/all_team-stats-base.pkl\", \"rb\")) as openfile:\n",
    "        data = pickle.load(openfile)\n",
    "    with (open(\"Data/\" + str(year) + \"/all_opponent-stats-base.pkl\", \"rb\")) as openfile:\n",
    "        opp_data = pickle.load(openfile)\n",
    "    return data, opp_data\n",
    "\n",
    "    #ratio, wins = convert_data_to_ratio(data)\n",
    "def convert_data_to_ratio(data):\n",
    "    wins = data[data.columns[-1]]\n",
    "    data = data.drop(labels='Win', axis=1)\n",
    "    columns = data.columns\n",
    "    for column in columns:\n",
    "        if '%' in column:\n",
    "            data = data.drop(column, axis=1)\n",
    "    away = data[data.columns[:len(data.columns)//2]]\n",
    "    home = data[data.columns[len(data.columns)//2:]]\n",
    "    ratio = []\n",
    "    for index, row in away.iterrows():\n",
    "        away_row = np.array(away.iloc[index], dtype=np.float)\n",
    "        home_row = np.array(home.iloc[index], dtype=np.float)\n",
    "        home_row[home_row == 0] = 1\n",
    "        ratio.append(away_row / home_row)\n",
    "    assert(len(ratio) == len(wins))\n",
    "    return ratio, wins\n",
    "def get_team_names(year):\n",
    "    rtn = []\n",
    "    standings_soup = \"https://www.basketball-reference.com/leagues/NBA_\" + str(year) + \"_standings.html\"\n",
    "    standings_soup = BeautifulSoup(urlopen(standings_soup), 'html.parser')\n",
    "    comment = standings_soup.find(\"div\",  id='all_expanded_standings')\\\n",
    "            .findAll(text=lambda text:isinstance(text, Comment))\n",
    "    extracted_comment = comment[0].extract()\n",
    "    standings_soup = BeautifulSoup(extracted_comment)\n",
    "    rows = standings_soup.find('tbody').findAll(\"tr\")\n",
    "    for row in rows:\n",
    "        rtn.append(row.find(\"td\", attrs={'data-stat': \"team_name\"}).getText())\n",
    "    return sorted(rtn)\n",
    "    \n",
    "    \n",
    "# training data: previous year's stats + current season stats\n",
    "def get_team_cumulative_stats(year):\n",
    "    team_stats = dict()\n",
    "    for initials, name in TEAMS:\n",
    "        with (open(\"Data/\" + str(year-1) + \"/\" + str(initials) + \\\n",
    "                   \"_season_game_basic_cumulative_stats.pkl\", \"rb\")) as openfile:    \n",
    "            team_stats[initials] = pickle.load(openfile)\n",
    "    return team_stats\n",
    "def get_total_games(team_stats):\n",
    "    num_games = 0\n",
    "    for key in team_stats:\n",
    "        num_games +=  team_stats[key].shape[0]\n",
    "    return num_games\n",
    "    \n",
    "#create training data\n",
    "def get_training_data(year):\n",
    "    training_data = []\n",
    "    results = []\n",
    "    team_names = get_team_names(year)\n",
    "    assert(team_names == get_team_names(year-1))\n",
    "    \n",
    "    team_cumulative_stats = get_team_cumulative_stats(year)\n",
    "    season_data, season_opp_data = get_season_data_per_poss(year-1)\n",
    "    season_data_dict = convert_season_data_to_dict(season_data, team_names)\n",
    "    season_opp_data_dict = convert_season_data_to_dict(season_opp_data, team_names)\n",
    "    for key in season_data_dict.keys():\n",
    "        assert(key in season_opp_data_dict)\n",
    "        season_data_dict[key] = np.concatenate((season_data_dict[key], season_opp_data_dict[key]), axis=None)\n",
    "    sample = \"https://www.basketball-reference.com/leagues/NBA_2019_games.html\"\n",
    "    year_soup = BeautifulSoup(urlopen(sample), 'html.parser')\n",
    "    months = year_soup.find(\"div\", attrs={'class': 'filter'})\n",
    "    months = months.findAll(\"a\")\n",
    "    months = [NBA_URL + month['href'] for month in months]\n",
    "    \n",
    "    for month in months:\n",
    "        month_soup = BeautifulSoup(urlopen(month), 'html.parser')\n",
    "        games = month_soup.find(\"table\", attrs={'id': 'schedule'}).find('tbody').findAll(\"tr\")\n",
    "        for game in games:\n",
    "            game_data = []\n",
    "            win = 0\n",
    "            if game.find('td') and game.find('td', attrs={'data-stat':'visitor_pts'}) \\\n",
    "                and game.find('td', attrs={'data-stat':'visitor_pts'}).getText():\n",
    "                away = game.find('td', attrs={'data-stat':'visitor_team_name'}).getText()\n",
    "                home = game.find('td', attrs={'data-stat':'home_team_name'}).getText()\n",
    "                away_pts = game.find('td', attrs={'data-stat':'visitor_pts'}).getText()\n",
    "                away_pts = int(away_pts)\n",
    "                home_pts = game.find('td', attrs={'data-stat':'home_pts'}).getText()\n",
    "                home_pts = int(home_pts)\n",
    "                game_data.extend(season_data_dict[away])\n",
    "                game_data.extend(season_data_dict[home])\n",
    "                assert(home_pts != away_pts)\n",
    "                if home_pts > away_pts:\n",
    "                    win = 1\n",
    "                results.append(win)\n",
    "                training_data.append(game_data)\n",
    "    assert(len(training_data) == len(results))\n",
    "    return training_data, results\n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "def convert_season_data_to_dict(pandas_frame, team_names):\n",
    "    pandas_frame.drop([column for column in list(pandas_frame) if '%' in column], inplace=True, axis=1)\n",
    "    pandas_frame.drop([column for column in list(pandas_frame) if 'FG' in column], inplace=True, axis=1)\n",
    "    pandas_frame.drop([column for column in list(pandas_frame) if 'PTS' in column], inplace=True, axis=1)\n",
    "    output = dict()\n",
    "    count = 0\n",
    "    for team in pandas_frame['Team']:\n",
    "        for team_name in team_names:\n",
    "            if team_name in team:\n",
    "                row = pandas_frame.iloc[count, 3:]\n",
    "                output[team_name] = row.values\n",
    "        count += 1\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /usr/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#get_training_data()\n",
    "data, results = get_training_data(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1307, 60)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data).astype(float)\n",
    "results = np.array(results).astype(float)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "(?, 30) (30, 2) (2,)\n",
      "(1176,)\n",
      "Epoch: 0001 cost= 0.000000106\n",
      "Epoch: 1001 cost= 0.000000106\n",
      "Epoch: 2001 cost= 0.000000106\n",
      "Epoch: 3001 cost= 0.000000106\n",
      "Epoch: 4001 cost= 0.000000106\n",
      "Accuracy: 0.57251906\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(shape=(None, data.shape[1]),  dtype=tf.float64, name='X')\n",
    "y = tf.placeholder(shape=(None,2), dtype=tf.float64, name='y')\n",
    "print(data.shape[1]/2)\n",
    "W1 = tf.Variable(np.random.rand(data.shape[1], int(data.shape[1]/2)), dtype=tf.float64)\n",
    "W2 = tf.Variable(np.random.rand(int(data.shape[1]/2), 2), dtype=tf.float64)\n",
    "b1 = tf.Variable(np.random.rand(int(data.shape[1]/2)))\n",
    "bo = tf.Variable(np.random.rand(2))\n",
    "A1 = tf.sigmoid(tf.add(tf.matmul(X,W1), b1))\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "#A1 = tf.nn.dropout(A1, keep_prob)\n",
    "print(A1.shape, W2.shape, bo.shape)\n",
    "predictions = tf.sigmoid(tf.add(tf.matmul(A1, W2), bo))\n",
    "\n",
    "#deltas = tf.square(y_est - y)\n",
    "#loss = tf.reduce_sum(deltas)\n",
    "\n",
    "\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(predictions),reduction_indices=[1]))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.005).minimize(cross_entropy)\n",
    "training_epochs = 5000\n",
    "\n",
    "train_data, test_data, train_results, test_results = train_test_split(data, results, test_size=0.1) \n",
    "print(train_results.shape)\n",
    "train_result = []\n",
    "for i in train_results:\n",
    "    if i == 0:\n",
    "        train_result.append([1,0])\n",
    "    else:\n",
    "        train_result.append([0,1])\n",
    "test_result = []\n",
    "for i in test_results:\n",
    "    if i == 0:\n",
    "        test_result.append([1,0])\n",
    "    else:\n",
    "        test_result.append([0,1])\n",
    "        \n",
    "total_batch = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(len(train_data)/ total_batch)\n",
    "        train_data_batches = np.array_split(train_data, total_batch)\n",
    "        train_result_batches = np.array_split(train_result, total_batch)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = train_data_batches[i], train_result_batches[i]\n",
    "            _, c = sess.run([optimizer, cross_entropy], \n",
    "                            feed_dict={\n",
    "                                X: batch_x, \n",
    "                                y: batch_y, \n",
    "                                keep_prob: 0.8\n",
    "                            })\n",
    "            avg_cost += c/ total_batch\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({X: test_data, y: test_result, keep_prob: 1.0}))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear results:  0.6656693281857798\n",
      "Polynomial results:  0.5677371238045099\n",
      "Logistic results:  0.6427159193939926\n",
      "SVM linear results:  0.6411570296276798\n",
      "SVM polynomial results:  0.6434734286800621\n",
      "SVM rbf results:  0.6243221900500131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlee/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "linear_results = []\n",
    "polynomial_results = []\n",
    "logistic_results = []\n",
    "svm_linear_results = []\n",
    "svm_polynomial_results = []\n",
    "svm_rbf_results = []\n",
    "for train_index, test_index in kFold.split(data):\n",
    "    regression_model = LinearRegression()\n",
    "    train_data, train_result = data[train_index], results[train_index]\n",
    "    test_data, test_result = data[test_index], results[test_index]\n",
    "    regression_model.fit(train_data, train_result)\n",
    "    test_prediction = regression_model.predict(test_data)\n",
    "\n",
    "    total = len(test_prediction)\n",
    "    correct = 0\n",
    "    for i in range(len(test_prediction)):\n",
    "        if test_prediction[i] > 0.5:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0\n",
    "        if pred == test_result[i]:\n",
    "            correct += 1\n",
    "    linear_results.append(float(correct)/ total)\n",
    "    rmse = mean_squared_error(test_result, test_prediction)\n",
    "    r2 = r2_score(test_result, test_prediction)\n",
    "    \n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree=2)\n",
    "    train_data_poly = polynomial_features.fit_transform(train_data)\n",
    "    test_data_poly = polynomial_features.fit_transform(test_data)\n",
    "    polynomial_model = LinearRegression()\n",
    "    polynomial_model.fit(train_data_poly,train_result)\n",
    "    polynomial_test_prediction = polynomial_model.predict(test_data_poly)\n",
    "    total = len(polynomial_test_prediction)\n",
    "    correct = 0\n",
    "    for i in range(len(polynomial_test_prediction)):\n",
    "        if polynomial_test_prediction[i] > 0.5:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0\n",
    "        if pred == test_result[i]:\n",
    "            correct += 1\n",
    "    polynomial_results.append(float(correct)/ total)\n",
    "    \n",
    "    rsme_polynomial = mean_squared_error(test_result, polynomial_test_prediction)\n",
    "    r2_polynomial = r2_score(test_result, polynomial_test_prediction)\n",
    "    \n",
    "# model evaluation\n",
    "    logistic_model = LogisticRegression()\n",
    "    logistic_model.fit(train_data, train_result)\n",
    "    logistic_test_prediction = logistic_model.predict(test_data)\n",
    "    test_prediction = logistic_test_prediction\n",
    "    \n",
    "    total = len(test_prediction)\n",
    "    correct = 0\n",
    "    for i in range(len(test_prediction)):\n",
    "        if test_prediction[i] > 0.5:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0\n",
    "        if pred == test_result[i]:\n",
    "            correct += 1\n",
    "    logistic_results.append(float(correct)/ total)\n",
    "    rmse_logistic = mean_squared_error(test_result, test_prediction)\n",
    "    r2_logistic = r2_score(test_result, test_prediction)\n",
    "    \n",
    "    svm_linear_model = SVC(kernel='linear')\n",
    "    svm_linear_model.fit(train_data, train_result)\n",
    "    test_prediction = svm_linear_model.predict(test_data)\n",
    "    total = len(test_prediction)\n",
    "    correct = 0\n",
    "    for i in range(len(test_prediction)):\n",
    "        if test_prediction[i] > 0.5:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0\n",
    "        if pred == test_result[i]:\n",
    "            correct += 1\n",
    "    svm_linear_results.append(float(correct)/total)\n",
    "'''\n",
    "    svm_polynomial_model = SVC(kernel='poly', degree = 2)\n",
    "    svm_polynomial_model.fit(train_data, train_result)\n",
    "    test_prediction = svm_polynomial_model.predict(test_data)\n",
    "    total = len(test_prediction)\n",
    "    correct = 0\n",
    "    for i in range(len(test_prediction)):\n",
    "        if test_prediction[i] > 0.5:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0\n",
    "        if pred == test_result[i]:\n",
    "            correct += 1\n",
    "    svm_polynomial_results.append(float(correct)/total)\n",
    "'''\n",
    "    svm_rbf_model = SVC(kernel='rbf')\n",
    "    svm_rbf_model.fit(train_data, train_result)\n",
    "    test_prediction = svm_rbf_model.predict(test_data)\n",
    "    total = len(test_prediction)\n",
    "    correct = 0\n",
    "    for i in range(len(test_prediction)):\n",
    "        if test_prediction[i] > 0.5:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0\n",
    "        if pred == test_result[i]:\n",
    "            correct += 1\n",
    "    svm_rbf_results.append(float(correct)/total)\n",
    "    \n",
    "\n",
    "# printing values\n",
    "    #print('Slope:' ,regression_model.coef_)\n",
    "    #print('Intercept:', regression_model.intercept_)\n",
    "print(\"Linear results: \", np.mean(linear_results))\n",
    "#print('Root mean squared error: ', rmse)\n",
    "#print('R2 score: ', r2)\n",
    "\n",
    "print(\"Polynomial results: \", np.mean(polynomial_results))\n",
    "#print('Polynomial Root mean squared error: ', rsme_polynomial)\n",
    "#print('Polynomial R2 score: ', r2_polynomial)\n",
    "\n",
    "print(\"Logistic results: \", np.mean(logistic_results))\n",
    "#print('Logistic Root mean squared error: ', rmse_logistic)\n",
    "#print('Logistic R2 score: ', r2_logistic)\n",
    "\n",
    "print(\"SVM linear results: \", np.mean(svm_linear_results))\n",
    "print(\"SVM polynomial results: \", np.mean(svm_polynomial_results))\n",
    "print(\"SVM rbf results: \", np.mean(svm_rbf_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
